<!DOCTYPE html>


<html lang="en" >


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="demon" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    pytorch å­¦ä¹  |  O
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/dist/main.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

</head>

</html>

<body>
  <div id="app">
    <main class="content on">
      <section class="outer">
  <article id="post-pytorch_learning" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  pytorch å­¦ä¹ 
</h1>
 

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/02/pytorch_learning/" class="article-date">
  <time datetime="2020-05-02T05:41:10.000Z" itemprop="datePublished">2020-05-02</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%AD%A6%E4%B9%A0/">å­¦ä¹ </a>
  </div>

      
      
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">1.7k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading timeâ‰ˆ</span>
            <span class="post-count">10 min</span>
        </span>
    </span>
</div>

      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    
    <div class="article-entry" itemprop="articleBody">
      
      

      
      <h3 id="pytorch-å­¦ä¹ "><a href="#pytorch-å­¦ä¹ " class="headerlink" title="pytorch å­¦ä¹ "></a>pytorch å­¦ä¹ </h3><h4 id="1-pytorchçš„ä¼˜ç‚¹"><a href="#1-pytorchçš„ä¼˜ç‚¹" class="headerlink" title="1. pytorchçš„ä¼˜ç‚¹"></a>1. pytorchçš„ä¼˜ç‚¹</h4><pre><code>è‡ªåŠ¨å¾®åˆ†
é›†æˆå¸¸ç”¨å‡½æ•°
æ‹¥æœ‰æ•°æ®å¤„ç†å‡½æ•°
å¤šç²¾åº¦è®­ç»ƒ</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">466</span>)</span><br><span class="line">np.random.seed(<span class="number">466</span>)</span><br></pre></td></tr></table></figure>

<h4 id="numpy-ndarray-ä¸-pytorch-Tensors-ä¹‹é—´çš„è”ç³»"><a href="#numpy-ndarray-ä¸-pytorch-Tensors-ä¹‹é—´çš„è”ç³»" class="headerlink" title="numpy ndarray ä¸ pytorch Tensors ä¹‹é—´çš„è”ç³»"></a>numpy ndarray ä¸ pytorch Tensors ä¹‹é—´çš„è”ç³»</h4>   <a id="more"></a>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_numpy = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">x_torch = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">print(<span class="string">'x_numpy,  x_torch'</span>)</span><br><span class="line">print(x_numpy,x_torch)</span><br><span class="line">print()</span><br></pre></td></tr></table></figure>

<pre><code>x_numpy,  x_torch
[1 2 3] tensor([1, 2, 3])</code></pre><p>â€‹    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'numpy ä¸ torch ä¹‹é—´çš„è½¬åŒ–'</span>)</span><br><span class="line">print(torch.from_numpy(x_numpy),x_torch.numpy())</span><br><span class="line">print()</span><br></pre></td></tr></table></figure>

<pre><code>numpy ä¸ torch ä¹‹é—´çš„è½¬åŒ–
tensor([1, 2, 3], dtype=torch.int32) [1 2 3]</code></pre><p>â€‹    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿ç®—æ“ä½œ</span></span><br><span class="line">y_numpy = np.array([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">y_torch = torch.tensor([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">print(<span class="string">'x+y'</span>)</span><br><span class="line">print(x_numpy+y_numpy,x_torch+y_torch)</span><br><span class="line">print()</span><br></pre></td></tr></table></figure>

<pre><code>x+y
[3 5 7] tensor([3, 5, 7])</code></pre><p>â€‹    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"mean along the 0th dimension"</span>)</span><br><span class="line">x_numpy = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4.</span>]])</span><br><span class="line">x_torch = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4.</span>]])</span><br><span class="line">print(np.mean(x_numpy, axis=<span class="number">0</span>), torch.mean(x_torch, dim=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<pre><code>mean along the 0th dimension
[2. 3.] tensor([2., 3.])</code></pre><h4 id="Tensor-view-ç”¨äºreshape-tensor"><a href="#Tensor-view-ç”¨äºreshape-tensor" class="headerlink" title="Tensor.view ç”¨äºreshape tensor"></a>Tensor.view ç”¨äºreshape tensor</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">N,C,W,H = <span class="number">10</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">5</span></span><br><span class="line">X = torch.randn(N,C,W,H)</span><br><span class="line"></span><br><span class="line">print(X.shape)</span><br><span class="line">print(X.view(N,C,<span class="number">5</span>*<span class="number">5</span>).shape)</span><br><span class="line">print(X.view(<span class="number">-1</span>,C,<span class="number">5</span>*<span class="number">5</span>).shape)</span><br></pre></td></tr></table></figure>

<pre><code>torch.Size([10, 3, 5, 5])
torch.Size([10, 3, 25])
torch.Size([10, 3, 25])</code></pre><h3 id="è®¡ç®—å›¾"><a href="#è®¡ç®—å›¾" class="headerlink" title="è®¡ç®—å›¾"></a>è®¡ç®—å›¾</h3><p>Whatâ€™s special about PyTorchâ€™s tensor object is that it implicitly creates a computation graph in the background. A computation graph is a a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients of all the variables of a computation graph in time on the same order it is to compute the function itself.</p>
<p>Consider the expression  ğ‘’=(ğ‘+ğ‘)âˆ—(ğ‘+1)  with values  ğ‘=2,ğ‘=1 . We can draw the evaluated computation graph as</p>
<p>In PyTorch, we can write this as<br><img src="/2020/05/02/pytorch_learning/tree-eval.png" alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor(<span class="number">2.0</span>,requires_grad=<span class="literal">True</span>) <span class="comment"># requires_grad è‡ªåŠ¨å¾®åˆ†å‚æ•°</span></span><br><span class="line">b = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">False</span>) <span class="comment"># è¾“å…¥Falseä¸è‡ªåŠ¨è®¡ç®—è®¡ç®—å›¾</span></span><br><span class="line">c = a+b</span><br><span class="line">d = b+<span class="number">1</span></span><br><span class="line">e = c*d</span><br><span class="line">print(<span class="string">'c'</span>,c)</span><br><span class="line">print(<span class="string">'d'</span>,d)</span><br><span class="line">print(<span class="string">'e'</span>,e)</span><br></pre></td></tr></table></figure>

<pre><code>c tensor(3., grad_fn=&lt;AddBackward0&gt;)
d tensor(2.)
e tensor(6., grad_fn=&lt;MulBackward0&gt;)</code></pre><h3 id="PyTorch-çš„è‡ªåŠ¨å¾®åˆ†æ¡†æ¶"><a href="#PyTorch-çš„è‡ªåŠ¨å¾®åˆ†æ¡†æ¶" class="headerlink" title="PyTorch çš„è‡ªåŠ¨å¾®åˆ†æ¡†æ¶"></a>PyTorch çš„è‡ªåŠ¨å¾®åˆ†æ¡†æ¶</h3><p>Now that we have seen that PyTorch keeps the graph around for us, letâ€™s use it to compute some gradients for us.</p>
<p>Consider the function  $ ğ‘“(ğ‘¥)=(ğ‘¥âˆ’2)^2 $.</p>
<p>Q: Compute $\frac{d}{dx} f(x)$ and then compute $fâ€™(1)$.</p>
<p>We make a <code>backward()</code> call on the leaf variable (<code>y</code>) in the computation, computing all the gradients of <code>y</code> at once.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (x<span class="number">-2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fp</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*(x<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>],requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = f(x)</span><br><span class="line">y.backward()  <span class="comment">#backward()ç”¨äºè®¡ç®—è¡¨è¾¾å¼ä¸­çš„æ‰€æœ‰æ¢¯åº¦</span></span><br><span class="line">print(<span class="string">'PyTorch è§£ä¸ºï¼š'</span>,x.grad)</span><br><span class="line">z = f(x) * f(x**<span class="number">2</span>)</span><br><span class="line">z.backward()</span><br><span class="line">print(<span class="string">'å¾®åˆ†è§£æè§£ä¸ºï¼š'</span>,fp(x))</span><br><span class="line">print(<span class="string">'PyTorch è§£ä¸ºï¼š'</span>,x.grad)</span><br></pre></td></tr></table></figure>

<pre><code>PyTorch è§£ä¸ºï¼š tensor([-2.])
å¾®åˆ†è§£æè§£ä¸ºï¼š tensor([-2.], grad_fn=&lt;MulBackward0&gt;)
PyTorch è§£ä¸ºï¼š tensor([-8.])</code></pre><p>It can also find gradients of functions.</p>
<p>Let $w = [w_1, w_2]^T$</p>
<p>Consider $g(w) = 2w_1w_2 + w_2\cos(w_1)$</p>
<p>Q: Compute $\nabla_w g(w)$ and verify $\nabla_w g([\pi,1]) = [2, \pi - 1]^T$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*w[<span class="number">0</span>]*w[<span class="number">1</span>] + w[<span class="number">1</span>]*torch.cos(w[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grad_g</span><span class="params">(w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor([<span class="number">2</span>*w[<span class="number">1</span>]-w[<span class="number">1</span>]*torch.sin(w[<span class="number">0</span>]),<span class="number">2</span>*w[<span class="number">0</span>]+torch.cos(w[<span class="number">0</span>])])</span><br><span class="line"></span><br><span class="line">w = torch.tensor([np.pi,<span class="number">1</span>],requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">z = g(w)</span><br><span class="line">z.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'è§£æè§£ï¼š'</span>, grad_g(w))</span><br><span class="line">print(<span class="string">'Torchè§£ï¼š'</span>, w.grad)</span><br></pre></td></tr></table></figure>

<pre><code>è§£æè§£ï¼š tensor([2.0000, 5.2832])
Torchè§£ï¼š tensor([2.0000, 5.2832])</code></pre><h3 id="ä½¿ç”¨æ¢¯åº¦"><a href="#ä½¿ç”¨æ¢¯åº¦" class="headerlink" title="ä½¿ç”¨æ¢¯åº¦"></a>ä½¿ç”¨æ¢¯åº¦</h3><p>Now that we have gradients, we can use our favorite optimization algorithm: gradient descent!</p>
<p>Let $f$ the same function we defined above.<br>$ f = (x-2)^2 $</p>
<p>Q: What is the value of $x$ that minimizes $f$?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">5.0</span>],requires_grad=<span class="literal">True</span>)</span><br><span class="line">step_size = <span class="number">0.4</span></span><br><span class="line">print(<span class="string">'iter,\tx,\tf(x),\tf\'(x),\tf\'(x) pytorch'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    y = f(x)</span><br><span class="line">    y.backward()</span><br><span class="line">    print(<span class="string">'&#123;&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;,\t&#123;:.3f&#125;'</span>.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))</span><br><span class="line">    </span><br><span class="line">    x.data = x.data - step_size * x.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#éœ€è¦æŠŠgradå€¼å½’é›¶ï¼Œä¸å½’é›¶çš„è¯ y çš„å€¼ä¼šç´¯ç§¯</span></span><br><span class="line">    x.grad.detach_() <span class="comment"># ä¸ºäº†æé«˜æ•ˆç‡</span></span><br><span class="line">    x.grad.zero_()</span><br></pre></td></tr></table></figure>

<pre><code>iter,    x,    f(x),    f&apos;(x),    f&apos;(x) pytorch
0,    5.000,    9.000,    6.000,    6.000
1,    2.600,    0.360,    1.200,    1.200
2,    2.120,    0.014,    0.240,    0.240
3,    2.024,    0.001,    0.048,    0.048
4,    2.005,    0.000,    0.010,    0.010
5,    2.001,    0.000,    0.002,    0.002
6,    2.000,    0.000,    0.000,    0.000
7,    2.000,    0.000,    0.000,    0.000
8,    2.000,    0.000,    0.000,    0.000
9,    2.000,    0.000,    0.000,    0.000</code></pre><h3 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><p>ä½¿ç”¨torchè¿›è¡Œçº¿æ€§å›å½’</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ„é€ äº†ä¸€ä¸ªçº¿æ€§å¸¦æœ‰å™ªéŸ³çš„data set</span></span><br><span class="line">d = <span class="number">2</span></span><br><span class="line">n = <span class="number">50</span></span><br><span class="line">X = torch.randn(n,d)</span><br><span class="line">true_w = torch.tensor([[<span class="number">-1.0</span>],[<span class="number">2.0</span>]])</span><br><span class="line">y = X @ true_w + torch.randn(n,<span class="number">1</span>)*<span class="number">0.1</span></span><br><span class="line">print(<span class="string">'X shape'</span>,X.shape)</span><br><span class="line">print(<span class="string">'y shape'</span>, y.shape)</span><br><span class="line">print(<span class="string">'w shape'</span>, true_w.shape)</span><br></pre></td></tr></table></figure>

<pre><code>X shape torch.Size([50, 2])
y shape torch.Size([50, 1])
w shape torch.Size([2, 1])</code></pre><h3 id="Note-dimensions"><a href="#Note-dimensions" class="headerlink" title="Note: dimensions"></a>Note: dimensions</h3><p>PyTorch does a lot of operations on batches of data. The convention is to have your data be of size $(N, d)$ where $N$ is the size of the batch of data.</p>
<h3 id="Sanity-check"><a href="#Sanity-check" class="headerlink" title="Sanity check"></a>Sanity check</h3><p>To verify PyTorch is computing the gradients correctly, letâ€™s recall the gradient for the RSS objective:</p>
<p>$$\nabla_w \mathcal{L}_{RSS}(w; X) = \nabla_w\frac{1}{n} ||y - Xw||_2^2 = -\frac{2}{n}X^T(y-Xw)$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(X,w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> X @ w</span><br><span class="line"></span><br><span class="line"><span class="comment"># norm æ±‚çš„æ˜¯çŸ©é˜µèŒƒæ•°</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rss</span><span class="params">(y,y_hat)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.norm(y-y_hat)**<span class="number">2</span>/n</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¢¯åº¦è§£æè§£ @ è¡¨ç¤ºçŸ©é˜µä¹˜æ³•</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grad_rss</span><span class="params">(X,y,W)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-2</span>*X.t()@(y-X @ w)/n</span><br><span class="line"></span><br><span class="line">w = torch.tensor([[<span class="number">1.0</span>],[<span class="number">0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">y_hat = model(X,w)</span><br><span class="line"></span><br><span class="line">loss = rss(y,y_hat)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Analytical gradient'</span>, grad_rss(X, y, w).detach().view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'PyTorch\'s gradient'</span>, w.grad.view(<span class="number">2</span>).numpy())</span><br></pre></td></tr></table></figure>

<pre><code>Analytical gradient [ 4.474982 -3.335253]
PyTorch&apos;s gradient [ 4.4749813 -3.3352537]</code></pre><p>Now that weâ€™ve seen PyTorch is doing the right think, letâ€™s use the gradients!</p>
<h2 id="Linear-regression-using-GD-with-automatically-computed-derivatives"><a href="#Linear-regression-using-GD-with-automatically-computed-derivatives" class="headerlink" title="Linear regression using GD with automatically computed derivatives"></a>Linear regression using GD with automatically computed derivatives</h2><p>We will now use the gradients to run the gradient descent algorithm.</p>
<p>Note: This example is an illustration to connect ideas we have seen before to PyTorchâ€™s way of doing things. We will see how to do this in the â€œPyTorchicâ€ way in the next example.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">step_size = <span class="number">0.4</span></span><br><span class="line">print(<span class="string">'iter,\t loss,\t w'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    y_hat = model(X,w)</span><br><span class="line">    loss = rss(y,y_hat)</span><br><span class="line">    </span><br><span class="line">    loss.backward()</span><br><span class="line">    w.data = w.data - step_size * w.grad</span><br><span class="line">    print(<span class="string">'&#123;&#125;,\t&#123;:.2f&#125;,\t&#123;&#125;'</span>.format(i, loss.item(), w.view(<span class="number">2</span>).detach().numpy()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># We need to zero the grad variable since the backward()</span></span><br><span class="line">    <span class="comment"># call accumulates the gradients in .grad instead of overwriting.</span></span><br><span class="line">    <span class="comment"># The detach_() is for efficiency. You do not need to worry too much about it.</span></span><br><span class="line">    w.grad.detach()</span><br><span class="line">    w.grad.zero_()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\ntrue w\t\t'</span>, true_w.view(<span class="number">2</span>).numpy())</span><br><span class="line">print(<span class="string">'estimated w\t'</span>, w.view(<span class="number">2</span>).detach().numpy())</span><br></pre></td></tr></table></figure>

<pre><code>iter,     loss,     w
0,    7.80,    [-2.5799851  2.668203 ]
1,    3.22,    [-1.1622744  2.2072678]
2,    0.08,    [-0.997594   2.0795758]
3,    0.02,    [-0.98061234  2.0375962 ]
4,    0.01,    [-0.97969574  2.022719  ]
5,    0.01,    [-0.9800115  2.0172987]
6,    0.01,    [-0.98020816  2.0153053 ]
7,    0.01,    [-0.98029053  2.0145698 ]
8,    0.01,    [-0.98032224  2.014298  ]
9,    0.01,    [-0.9803341  2.0141976]
10,    0.01,    [-0.98033845  2.0141604 ]
11,    0.01,    [-0.98034006  2.0141468 ]
12,    0.01,    [-0.98034066  2.0141418 ]
13,    0.01,    [-0.9803409  2.01414  ]
14,    0.01,    [-0.98034096  2.0141392 ]
15,    0.01,    [-0.980341  2.014139]
16,    0.01,    [-0.980341  2.014139]
17,    0.01,    [-0.980341  2.014139]
18,    0.01,    [-0.980341  2.014139]
19,    0.01,    [-0.980341  2.014139]

true w         [-1.  2.]
estimated w     [-0.980341  2.014139]</code></pre><h3 id="Neural-Network-Basics-in-PyTorch"><a href="#Neural-Network-Basics-in-PyTorch" class="headerlink" title="Neural Network Basics in PyTorch"></a>Neural Network Basics in PyTorch</h3><p>fitting a simple neural network to the data </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">d = <span class="number">1</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">X = torch.rand(n,d)</span><br><span class="line">y = <span class="number">4</span>* torch.sin(np.pi*X)*torch.cos(<span class="number">6</span>*np.pi*X**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X.numpy(),y.numpy())</span><br><span class="line">plt.title(<span class="string">'plot of $f(x)$'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'$x$'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'$y$'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/05/02/pytorch_learning/output_25_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">step_size = <span class="number">0.05</span></span><br><span class="line">iter_times = <span class="number">12000</span></span><br><span class="line">n_hidden_1 = <span class="number">32</span></span><br><span class="line">n_hidden_2 = <span class="number">32</span></span><br><span class="line">d_out = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">neural_network = nn.Sequential(</span><br><span class="line">                                nn.Linear(d,n_hidden_1),</span><br><span class="line">                                nn.Tanh(),</span><br><span class="line">                                nn.Linear(n_hidden_1,n_hidden_2),</span><br><span class="line">                                nn.Tanh(),</span><br><span class="line">                                nn.Linear(n_hidden_2,d_out))</span><br><span class="line"></span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">optim = torch.optim.SGD(neural_network.parameters(),lr=step_size)</span><br><span class="line">print(<span class="string">'iter, \t loss'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(iter_times):</span><br><span class="line">    y_hat = neural_network(X)</span><br><span class="line">    loss = loss_func(y_hat,y)</span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optim.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> ==<span class="number">0</span> :</span><br><span class="line">        print(<span class="string">'&#123;&#125;,\t&#123;:.2f&#125;'</span>.format(i, loss.item()))</span><br></pre></td></tr></table></figure>

<pre><code>iter,      loss
0,    4.36
1000,    2.60
2000,    1.08
3000,    0.62
4000,    0.23
5000,    0.12
6000,    0.06
7000,    0.05
8000,    0.03
9000,    0.02
10000,    0.00
11000,    0.01</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X_grid = torch.from_numpy(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">50</span>)).float().view(<span class="number">-1</span>,d)</span><br><span class="line">y_hat = neural_network(X_grid)</span><br><span class="line">plt.scatter(X.numpy(), y.numpy())</span><br><span class="line">plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), <span class="string">'r'</span>)</span><br><span class="line">plt.title(<span class="string">'plot of $f(x)$ and $\hat&#123;f&#125;(x)$'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'$x$'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'$y$'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/05/02/pytorch_learning/output_27_0.png" alt="png"></p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
        <div class="declare">
          <ul class="post-copyright">
            <li>
              <i class="ri-copyright-line"></i>
              <strong>Copyrightï¼š </strong>
              Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
            </li>
          </ul>
        </div>
        
    <footer class="article-footer">
      
          
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        åˆ†äº«
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>æ‰«ä¸€æ‰«ï¼Œåˆ†äº«åˆ°å¾®ä¿¡</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://huyiph.xyz/2020/05/02/pytorch_learning/" alt="å¾®ä¿¡åˆ†äº«äºŒç»´ç ">
    </div>
</div>

<div id="share-mask"></div>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deeplearning/" rel="tag">deeplearning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li></ul>


    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2021/01/07/src/w0_background/intro/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
        <div class="article-nav-title">
          
            src/w0_background/intro
          
        </div>
      </a>
    
    
      <a href="/2020/04/11/20200411/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
        <div class="article-nav-title">20200411-æ—¥å¿—</div>
      </a>
    
  </nav>


  

  
  
<!-- valineè¯„è®º -->
<div id="vcomments-box">
    <div id="vcomments">
    </div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#vcomments',
        app_id: '',
        app_key: '',
        path: window.location.pathname,
        notify: 'false',
        verify: 'false',
        avatar: 'monsterid',
        placeholder: 'ç»™æˆ‘çš„æ–‡ç« åŠ ç‚¹è¯„è®ºå§~',
        recordIP: true
    });
    const infoEle = document.querySelector('#vcomments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
        infoEle.childNodes.forEach(function (item) {
            item.parentNode.removeChild(item);
        });
    }
</script>
<style>
    #vcomments-box {
        padding: 5px 30px;
    }

    @media screen and (max-width: 800px) {
        #vcomments-box {
            padding: 5px 0px;
        }
    }

    #vcomments-box #vcomments {
        background-color: #fff;
    }

    .v .vlist .vcard .vh {
        padding-right: 20px;
    }

    .v .vlist .vcard {
        padding-left: 10px;
    }
</style>

  

  
  
  
  
  

</article>
</section>
      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2020-2021
        huyi
      </li>
      <li>
        
        Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <span>
  <i>PV:<span id="busuanzi_value_page_pv"></span></i>
  <i>UV:<span id="busuanzi_value_site_uv"></span></i>
</span>
        
      </li>
      
      <li>
        <!-- cnzzç»Ÿè®¡ -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>

      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="O"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">ä¸»é¡µ</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">å½’æ¡£</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">åˆ†ç±»</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">æ ‡ç­¾</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/logs/">æ—¥å¿—</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2020/about">å…³äºæˆ‘</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>è¯·æˆ‘å–æ¯å’–å•¡å§~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">æ”¯ä»˜å®</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">å¾®ä¿¡</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script>
  try {
    var typed = new Typed("#subtitle", {
      strings: ['----------------------', '', ''],
      startDelay: 0,
      typeSpeed: 200,
      loop: true,
      backSpeed: 100,
      showCursor: true
    });
  } catch (err) {
  }

</script>




<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>



<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // sliderå±•å¼€çŠ¶æ€
                // todo: è¿™æ ·ä¸å¥½ï¼Œåé¢æ”¹æˆçŠ¶æ€
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // è·å¾—åŸå›¾å°ºå¯¸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true
  }
</script>



    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
        
    




<script src="/js/busuanzi-2.3.pure.min.js"></script>



<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>




  <script src='https://unpkg.com/mermaid@v8.4.8/dist/mermaid.min.js'></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>


    
  </div>
</body>

</html>